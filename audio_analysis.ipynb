{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinic/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import subprocess\n",
    "import json\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    audio = whisper.load_audio(audio_file,sr=16000)\n",
    "    audio_tensor = torch.from_numpy(audio).to(torch.float32)\n",
    "    result = model.transcribe(audio_tensor, fp16=False)['text']\n",
    "    return result\n",
    "\n",
    "def listfiles():\n",
    "    arr = os.listdir(\"ligacoes\")\n",
    "    return arr\n",
    "\n",
    "files = listfiles()\n",
    "\n",
    "for file in files:\n",
    "    if(file.split(\".\")[1]==\"mp3\"):\n",
    "       subprocess.check_call([\"whisper\", \"/home/vinic/development/python/DasaDados/ligacoes/\" + file, \"--language=Portuguese\", \"--fp16=False\"]) \n",
    "\n",
    "#transcribe_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Analisys   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listfiles():\n",
    "    arr = os.listdir(\"transcricoes\")\n",
    "    return arr\n",
    "\n",
    "with open('config.json') as json_data:\n",
    "    config = json.load(json_data)   \n",
    "\n",
    "text_files = listfiles()\n",
    "responses = []\n",
    "\n",
    "for file in text_files:\n",
    "\n",
    "    print(\"processando \" + file)\n",
    "\n",
    "    if( len(file.split(\".mp3.\"))>1 and file.split(\".mp3.\")[1]==\"txt\"):\n",
    "\n",
    "        with open(\"transcricoes/\" + file) as f: filetext = f.read()\n",
    "        json_obj={}\n",
    "\n",
    "        # Chamada GenAI com Prompt Inicial\n",
    "        content = config[\"prompt_inicial\"].replace(\"[[transcricao]]\", \"[[\" + filetext + \"]]\")[:5000]\n",
    "        response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': content\n",
    "            },\n",
    "        ])\n",
    "        #print(response.message.content)\n",
    "        \n",
    "        try:\n",
    "            json_obj = json.loads(response.message.content)\n",
    "            json_obj[\"file_name\"] = file\n",
    "            json_obj[\"token_in\"] = response.prompt_eval_count\n",
    "            json_obj[\"token_out\"] = response.eval_count\n",
    "\n",
    "        except:\n",
    "            f = open(\"error.txt\", \"a\")\n",
    "            f.write(file)\n",
    "            f.write(response.message.content)\n",
    "            f.close()\n",
    "\n",
    "        # Caso seja agendamento, validar informações adicionais\n",
    "        if( \"tipo\" in json_obj and json_obj[\"tipo\"]==\"Agendamento\"):\n",
    "\n",
    "            json_obj_agendamento={}\n",
    "\n",
    "            # Chamada GenAI com Prompt de Agendamento\n",
    "            content = config[\"prompt_agendamento\"].replace(\"[[transcricao]]\", \"[[\" + filetext + \"]]\")[:5000]\n",
    "            response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': content\n",
    "                },\n",
    "            ])\n",
    "            #print(response.message.content)\n",
    "            \n",
    "            try:\n",
    "                json_obj_agendamento = json.loads(response.message.content)\n",
    "\n",
    "                json_obj[\"tipo_atendimento\"]=json_obj_agendamento[\"tipo_atendimento\"]\n",
    "                json_obj[\"nome_convenio\"]=json_obj_agendamento[\"nome_convenio\"]\n",
    "                json_obj[\"laboratorio\"]=json_obj_agendamento[\"laboratorio\"]\n",
    "                json_obj[\"oferta\"]=json_obj_agendamento[\"oferta\"]\n",
    "\n",
    "            except:\n",
    "                f = open(\"error.txt\", \"a\")\n",
    "                f.write(file)\n",
    "                f.write(response.message.content)\n",
    "                f.close()\n",
    "\n",
    "        responses.append(json_obj)\n",
    "        df = pd.DataFrame(responses)\n",
    "        df.to_csv('output.csv', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listfiles():\n",
    "    arr = os.listdir(\"transcricoes\")\n",
    "    return arr\n",
    "\n",
    "with open('config.json') as json_data:\n",
    "    config = json.load(json_data)   \n",
    "\n",
    "text_files = listfiles()\n",
    "responses = []\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "for file in text_files:\n",
    "\n",
    "    print(\"processando \" + file)\n",
    "\n",
    "    # Find item classification on CSV\n",
    "    item_output_csv = df.loc[df[\"file_name\"]==file, [\"tipo\"]]\n",
    "    \n",
    "    # Process items identified as AGENDAMENTO\n",
    "    if( len(file.split(\".\"))>1 and file.split(\".mp3.\")[1]==\"txt\" and  len(item_output_csv) > 0 and item_output_csv.iloc[0][\"tipo\"]==\"Agendamento\"):\n",
    "        print(\"Agendamento, processo iniciado\")\n",
    "\n",
    "        with open(\"transcricoes/\" + file) as f: filetext = f.read()\n",
    "        json_obj={}\n",
    "\n",
    "        # Chamada GenAI com Prompt de Exames\n",
    "        content = config[\"prompt_agendamento_exames\"].replace(\"[[transcricao]]\", \"[[\" + filetext + \"]]\")[:5000]\n",
    "        response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': content\n",
    "            },\n",
    "        ])\n",
    "        #print(response.message.content)\n",
    "        \n",
    "        try:\n",
    "            array_exames = response.message.content.split(\",\")\n",
    "            \n",
    "            for exame in array_exames:\n",
    "                f = open(\"output_exames.csv\", \"a\")\n",
    "                f.write(file + ',\"' +  exame.replace(\"\\n\", \"\") + '\", ' + str(response.prompt_eval_count) + ', ' + str(response.eval_count)  + '\\n')\n",
    "                f.close()\n",
    "\n",
    "\n",
    "        except:\n",
    "            f = open(\"error.txt\", \"a\")\n",
    "            f.write(file)\n",
    "            f.write(response.message.content)\n",
    "            f.close()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schedule Fail Reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listfiles():\n",
    "    arr = os.listdir(\"transcricoes\")\n",
    "    return arr\n",
    "\n",
    "with open('config.json') as json_data:\n",
    "    config = json.load(json_data)   \n",
    "\n",
    "text_files = listfiles()\n",
    "responses = []\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "for file in text_files:\n",
    "\n",
    "    print(\"processando \" + file)\n",
    "\n",
    "    # Find item classification on CSV\n",
    "    item_output_csv = df.loc[df[\"file_name\"]==file, [\"tipo\", \"resolvido\"]]\n",
    "    \n",
    "    # Process items identified as AGENDAMENTO\n",
    "    if( len(file.split(\".\"))>1 and file.split(\".mp3.\")[1]==\"txt\" and  len(item_output_csv) > 0 and item_output_csv.iloc[0][\"tipo\"]==\"Agendamento\" and item_output_csv.iloc[0][\"resolvido\"]==False):\n",
    "        print(\"Agendamento, processo iniciado\")\n",
    "\n",
    "        with open(\"transcricoes/\" + file) as f: filetext = f.read()\n",
    "        json_obj={}\n",
    "\n",
    "        # Chamada GenAI com Prompt de Exames\n",
    "        content = config[\"prompt_agendamento_motivo_negativo\"].replace(\"[[transcricao]]\", \"[[\" + filetext + \"]]\")[:5000]\n",
    "        response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': content\n",
    "            },\n",
    "        ])\n",
    "        #print(response.message.content)\n",
    "        \n",
    "        try:\n",
    "            f = open(\"output_schedule_false.csv\", \"a\")\n",
    "            f.write(file + ',\"' +   response.message.content   + '\"\\n')\n",
    "            f.close()\n",
    "\n",
    "\n",
    "        except:\n",
    "            f = open(\"error.txt\", \"a\")\n",
    "            f.write(file)\n",
    "            f.write(response.message.content)\n",
    "            f.close()\n",
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
